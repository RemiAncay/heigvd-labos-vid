---
title: "VID"
subtitle: "German Credit Data"
author:
  - name: Rémi Ançay & Lucas Charbonnier
highlight-style: github
format:
  html:
    theme: cosmo
    monobackgroundcolor: rgb(255,250,240)
    toc: true
    toc-location: left
    #reference-location: margin
    reference-location: document
    code-line-numbers: true
date: 'last-modified'
date-format: '[This version:] MMMM D, YYYY'
number-sections: false
editor: 
  visual
execute:
  echo: true
  message: true
  warning: false
  output: true
---

## Introduction

Dans ce projet, il est question de données bancaires.
Nous devons déterminer quelles variables explicatives sont représentatives pour déterminer si un prêt bancaire est attribué ou non.

### Gestion des bibliothèques

Voici la liste des bibliothèques utilisées pour ce projet.

```{r}
#| output: false

download = FALSE

#r = getOption("repos")
#r["CRAN"] = "http://cran.us.r-project.org"
#options(repos = r)

if(download) {
  install.packages("ggResidpanel")
  install.packages("tidyverse")
  install.packages("ggrepel")
  install.packages("GGally")
  install.packages("rgl")
  install.packages("scatterplot3d")
  install.packages("readxl")
  install.packages("psych") 
  install.packages("leaps")
  install.packages("pROC")
}

library("ggResidpanel")
library("tidyverse")
library("ggrepel")
library("GGally")
library("rgl")
library("scatterplot3d")
library("readxl")
library("psych")
library("leaps")
library("pROC")

```

## Chargement des données
```{r}
# Chargement des données
GermanCredit <- read.csv("data/GermanCredit.csv", sep = ";")

GermanCredit = na.omit(GermanCredit)

```

Après une brève analyse exploratoire des données, nous avons remarqué qu'il existait des valeurs "NA" dans le fichier. Ces valeurs semblent survenir de manière aléatoire, nous avons donc choisi de les supprimer.

Il existe aussi plusieurs erreurs dans les données que nous avons rectifiées :

- Dans `DURATION` il existait une valeur de -6 (mise à 6)
- Dans `MALE_SINGLE` il existait une valeur de 2 (mise à 1)
- Dans `GUARANTOR` il existait une valeur de -1 (mise à 1)
- Dans `AGE` il existe une valeur à 151 (mise à 51)
- Selon la documentation du dataset, `PRESENT_RESIDENT` est une variable catégorielle censé prendre des valeurs entre 0 et 3 (compris) mais dans les faits, ces valeurs vont de 1 à 4. Nous avons décidé de ne pas rectifier cette "erreur" car en pratique ça ne fait aucune différence.

### Résumé
```{r}
describe(GermanCredit)
```

## Regression linéaire
Nous avons créé un modèle linéaire de régression utilisant toutes nos variables explicatives afin d'avoir une première idée de l'importance de celles-ci. Voici le résumé donné par le modèle.

```{r}
# LM utilisant toutes les variables explicative
GermanCredit.lm = lm(RESPONSE~., data=GermanCredit)
#coef(GermanCredit.lm)
summary(GermanCredit.lm)
```

Nous avons décidé d'utiliser les critère d'information `BIC`, `Cp` ainsi que le coefficient de détermination ajusté ${R_adj}^2$. Ci-dessous, les graphes des ensemble de variables explicatives retenus par la fonction `regsubsets`:

```{r}
#Trouver les meilleurs variables
choix <- regsubsets(RESPONSE~., data=GermanCredit, nbest=1, nvmax=11)

plot(choix, scale="adjr2", col="midnightblue")
plot(choix, scale="bic", col="midnightblue")
plot(choix, scale="Cp", col="midnightblue")


#leaps <- regsubsets(RESPONSE~., data=GermanCredit, nbest=10)
#summary(leaps)
```

On peut constater que la plupart des colonnes ne sont jamais prises en compte et également que les 3 colonnes `CHK_ACCT`, `DURATION` et `HISTORY` sont souvent retenues, peu importe le critère d'information utilisé.

Nous avons ensuite créé un nouveau modèle utilisant seulement ces 3 meilleurs variables explicatives :

```{r}
#LM avec les 3 meilleurs variables
GermanCredit.lmReduced = lm(RESPONSE~CHK_ACCT+DURATION+HISTORY, data=GermanCredit)
summary(GermanCredit.lmReduced)
```

Malheureusement, avec un coefficient de détermination $R^2$ de `0.1805`, les résultats sont moins bon qu'avec le modèle précédent ($R^2 = 0.2712$).

Nous avons également essayé de prendre plus de variables (parmis celles qui ont été retenues dans les graphiques ci-dessus) :

```{r}
GermanCredit.lmReduced2 = lm(RESPONSE~CHK_ACCT+DURATION+HISTORY+NEW_CAR+EDUCATION+SAV_ACCT+INSTALL_RATE+MALE_SINGLE+GUARANTOR+OTHER_INSTALL, data=GermanCredit)
summary(GermanCredit.lmReduced2)
```

Avec un coefficient de détermination de `0.2396`, ce nouveau modèle se rapproche du modèle initial qui comportait toutes les variables explicatives.

On peut donc en conclure que la mauvaise performance de notre modèle n'est pas dû à la forte présence de bruit mais que c'est plutôt le modèle en question qui n'est pas adapté.

Nous avons donc décidé de changer de modèle et d'utiliser une regression logistique.

## Regression logistique

Une bonne partie des variables sont catégorielles. Afin que la regression logistique les traite correctement, nous devons diviser les colonnes catégorielles en plusieurs sous-colonnes pour que le modèle puisse distinguer celles qui sont représentatives des autres.

En R, cela se fait avec la fonction `factor()` :
```{r}
# Séparation des variables catégorielles
GermanCredit$CHK_ACCT = factor(GermanCredit$CHK_ACCT)
GermanCredit$HISTORY = factor(GermanCredit$HISTORY)
GermanCredit$SAV_ACCT = factor(GermanCredit$SAV_ACCT)
GermanCredit$EMPLOYMENT = factor(GermanCredit$EMPLOYMENT)
GermanCredit$PRESENT_RESIDENT = factor(GermanCredit$PRESENT_RESIDENT)
GermanCredit$JOB = factor(GermanCredit$JOB)
```

Création du modèle de regression logistique avec toutes les variables disponibles :
```{r}
# GLM avec toutes nos variables
GermanCredit.glm = glm(RESPONSE~., data=GermanCredit, family = binomial)
#coef(GermanCredit.glm)
summary(GermanCredit.glm)
```

Après analyse du résumé ci-dessus, nous avons reconstruit un modèle, mais cette fois avec toutes les variables qui ont un niveau de signification de 5%.

```{r}

# GLM avec les variables représentatives
GermanCredit.glmReduced = glm(RESPONSE~CHK_ACCT+DURATION+HISTORY+NEW_CAR+EDUCATION+AMOUNT+SAV_ACCT+INSTALL_RATE+MALE_SINGLE+GUARANTOR+PRESENT_RESIDENT+OTHER_INSTALL+TELEPHONE+FOREIGN, data=GermanCredit, family = binomial)

summary(GermanCredit.glmReduced)
```

On peut utiliser le critère AIC pour comparer ces deux modèles. Le second obtient un AIC de `963.39` contre un AIC de `975.37` pour le premier.

## Vérification du modèle

Maintenant la régression logistique effectuée, nous allons tracer quelques graphes qui nous permettront de vérifier si le modèle est adéquat et qu'il est bien ajusté.

### Résidus de la régression
On commence par affichés l'histogramme des résidus :
```{r}
residuals <- residuals(GermanCredit.glmReduced, type="deviance")

ggplot(data.frame(residuals), aes(x = residuals)) +
  geom_histogram(binwidth = 0.5, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogramme des résidus", x = "Résidus de déviance", y = "Fréquence") +
  theme_minimal()
```

Dans l'idéal, on devrait obtenir une distribution normale, unimodale, symétrique et centrée proche de zéro. Notre distribution est bimodale, pas symétrique et pas centré sur zéro.

Les causes possibles de ce problème peuvent être :
- Il existe des dépendances entre certaines de nos variables non-détectées par le modèle. Étant donné qu'il s'agit de données bancaires, cela est très probable car il y a sûrement une corrélation entre la richesse d'une personne et la quantité de crédit de demandé (par exemple)
- La forte présence de valeurs atypiques
- Une hétéroscédasticité, soit une variance inégale des résidus.

### Coefficients et intervalles de confiance
```{r}
# Extract coefficients and confidence intervals
coef_df <- as.data.frame(summary(GermanCredit.glmReduced)$coefficients)
coef_df$variable <- rownames(coef_df)
colnames(coef_df) <- c("Estimate", "Std.Error", "z.value", "p.value", "variable")

# Create the plot
ggplot(coef_df, aes(x = reorder(variable, Estimate), y = Estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = Estimate - 1.96 * Std.Error, ymax = Estimate + 1.96 * Std.Error), width = 0.2) +
  coord_flip() +
  labs(title = "Coefficient Plot", x = "Variables", y = "Estimates") +
  theme_minimal()
```

Dans l'idéal, on ne devrait avoir que des variables dont la variance ne comprend pas zéro. Dans notre cas, il y a plusieurs variables qui ne respectent pas cette rêgle :
- `SAV_ACCT2`
- `SAV_ACCT1`
- `HISTORY1`
- `PRESENT_RESIDENT4`
- `PRESENT_RESIDENT3`
Malheureusement, nous ne pouvons pas enever ces variables car elles sont des facteurs de leur variable originale (comme l'indique le numéro à la fin du nom).

Il y aussi `DURATION` et `AMOUNT` qui sont très proches de zéro mais on obtient un AIC moins grand lorsque on retire ces deux variables de la régression logistique.

### Courbe ROC (Receiver Operating Characteristic)
```{r}
# Predict probabilities
prob <- predict(GermanCredit.glmReduced, type = "response")

# Create ROC curve
roc_curve <- roc(GermanCredit$RESPONSE, prob)

# Plot ROC curve
ggroc(roc_curve) +
  labs(title = "ROC Curve glm", x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal()
```

TODO

## Analyse des résultats

### AGE
```{r}
# Add a new column for predicted probabilities
GermanCredit$predicted_prob <- predict(GermanCredit.glm, type = "response")

# Create the plot
ggplot(GermanCredit, aes(x = AGE, y = predicted_prob)) +
  geom_point(alpha = 0.5) +  # Scatter plot of predicted probabilities
  geom_smooth(method = "loess", color = "blue") +  # Smoothed line
  labs(title = "Predicted Probabilities vs Age",
       x = "Age",
       y = "Predicted Probability") +
  theme_minimal()
```

### CHK_ACCT
```{r}
# Add a new column for predicted probabilities
GermanCredit$predicted_prob <- predict(GermanCredit.glm, type = "response")

# Create the plot
ggplot(GermanCredit, aes(x = CHK_ACCT, y = predicted_prob)) +
  geom_point(alpha = 0.5) +  # Scatter plot of predicted probabilities
  geom_smooth(method = "loess", color = "blue") +  # Smoothed line
  labs(title = "Predicted Probabilities vs CHK_ACCT",
       x = "CHK_ACCT",
       y = "Predicted Probability") +
  theme_minimal()
```

### Boxplots
```{r}
# Create a boxplot for each level of CHK_ACCT
ggplot(GermanCredit.glm, aes(x = as.factor(CHK_ACCT), y = RESPONSE)) +
  geom_boxplot() +
  labs(title = "Boxplot of RESPONSE by CHK_ACCT Levels",
       x = "CHK_ACCT",
       y = "RESPONSE") +
  theme_minimal()
```
```{r}
# Boxplot for DURATION
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = DURATION)) +
  geom_boxplot() +
  labs(title = "Boxplot of DURATION by RESPONSE",
       x = "RESPONSE",
       y = "DURATION") +
  theme_minimal()

# Boxplot for MALE_SINGLE
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = MALE_SINGLE)) +
  geom_boxplot() +
  labs(title = "Boxplot of MALE_SINGLE by RESPONSE",
       x = "RESPONSE",
       y = "MALE_SINGLE") +
  theme_minimal()

# Boxplot for AMOUNT
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = AMOUNT)) +
  geom_boxplot() +
  labs(title = "Boxplot of AMOUNT by RESPONSE",
       x = "RESPONSE",
       y = "AMOUNT") +
  theme_minimal()

# Boxplot for AGE
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = AGE)) +
  geom_boxplot() +
  labs(title = "Boxplot of AGE by RESPONSE",
       x = "RESPONSE",
       y = "AGE") +
  theme_minimal()
```

### Histogram
```{r}
# Create histograms for each level of CHK_ACCT
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE))) +
  geom_histogram(stat = "count", fill = "steelblue", color = "black") +
  facet_wrap(~ CHK_ACCT) +
  labs(title = "Histogram of RESPONSE by CHK_ACCT Levels",
       x = "RESPONSE",
       y = "Count") +
  theme_minimal()
```

```{r}
# Create a stacked bar plot of the proportion of RESPONSE for each CHK_ACCT level
ggplot(GermanCredit.glm, aes(x = as.factor(CHK_ACCT), fill = as.factor(RESPONSE))) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Proportion of RESPONSE by CHK_ACCT Levels",
       x = "CHK_ACCT",
       y = "Proportion",
       fill = "RESPONSE") +
  theme_minimal()
```

## Conclusion

Avec tout ces modèles, nous pouvons déduire certaines hypothèse :

- Le modèle de régression logistique est plus adapté lorsque nous utilisons plusieurs type de variables.
- Un modèle utilisant en entrée seulement les variables explicatives significatives est meilleur qu'un model utilisant simplement toutes les variables.

Nous pouvons aussi déduire grâce a nos résultats et aux différents graphique l'importance des différentes variables.
Nous pouvons citer :

- `CHK_ACCT`
- `AMOUNT`
- Ou encore `DURATION`

Néanmoins il y a quelques variables qui semblaient être importantes, mais qui le sont pas du tout ou très peu.
Nous avons : 

- `AGE`
- Ou encore `EMPLOYMENT`