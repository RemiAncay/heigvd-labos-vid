---
title: "VID"
subtitle: "German Credit Data"
author:
  - name: Rémi Ançay & Lucas Charbonnier
highlight-style: github
format:
  html:
    theme: cosmo
    monobackgroundcolor: rgb(255,250,240)
    toc: true
    toc-location: left
    #reference-location: margin
    reference-location: document
    code-line-numbers: true
date: 'last-modified'
date-format: '[This version:] MMMM D, YYYY'
number-sections: false
editor: 
  visual
execute:
  echo: true
  message: true
  warning: false
  output: true
---

## Introduction

Ce projet consiste en la recherche et l'analyse des meilleures variables explicatives d'un dataset concernant le risque associé à des crédits bancaires. Le but est donc de trouver les meilleurs indicateurs permettant d'estimer le risque associé à un crédit.
Il s'agit d'un exercice, nos résultats ne sortiront pas du cadre de ce travail et ne seront pas appliqués à un cadre réel.

### Gestion des bibliothèques

Nous avons commencé par établir la liste des bibliothèques nécessaire à l'exécution de notre code.

```{r}
#| output: false

download = FALSE

#r = getOption("repos")
#r["CRAN"] = "http://cran.us.r-project.org"
#options(repos = r)

libraries = list(
  "ggResidpanel",
  "tidyverse",
  "ggrepel",
  "GGally",
  "rgl",
  "scatterplot3d",
  "readxl",
  "psych",
  "leaps",
  "pROC"
)

for (lib in libraries) {
  if(download)
    install.packages(lib)
  library(lib, character.only = TRUE)
}

```

## Chargement des données
```{r}
# Chargement des données
GermanCredit <- read.csv("data/GermanCredit.csv", sep = ";")
```

Après une brève analyse exploratoire des données, nous avons remarqué qu'il existait des valeurs "NA" dans le fichier. Ces valeurs semblent survenir de manière aléatoire, nous avons donc choisi de les supprimer.

```{r}
GermanCredit = na.omit(GermanCredit)
```

Il existe aussi plusieurs erreurs dans les données :

- Dans `DURATION` il existait une valeur de -6 (mise à 6)
- Dans `MALE_SINGLE` il existait une valeur de 2 (mise à 1)
- Dans `GUARANTOR` il existait une valeur de -1 (mise à 1)
- Dans `AGE` il existe une valeur à 151 (mise à 51)
- Selon la documentation du dataset, `PRESENT_RESIDENT` est une variable catégorielle censé prendre des valeurs entre 0 et 3 (compris) mais dans les faits, ces valeurs vont de 1 à 4. Nous avons décidé de ne pas rectifier cette "erreur" car en pratique ça ne fait aucune différence pour l'entraînement du modèle.

Nous avons effectué ces modifications manuellement dans le fichier CSV.

### Résumé
```{r}
describe(GermanCredit)
```

## Regression linéaire
Nous avons d'abord créé un modèle linéaire de régression utilisant toutes nos variables explicatives afin d'avoir une première idée de l'importance de celles-ci. Voici le résumé donné par le modèle.

```{r}
# LM utilisant toutes les variables explicative
GermanCredit.lm = lm(RESPONSE~., data=GermanCredit)
#coef(GermanCredit.lm)
summary(GermanCredit.lm)
```

Nous avons décidé d'utiliser les critère d'information `BIC`, `Cp` ainsi que le coefficient de détermination ajusté ${R_{adj}}^2$. Ci-dessous, les graphes des ensemble de variables explicatives retenus par la fonction `regsubsets`:

```{r}
# Trouver les meilleurs variables
choix <- regsubsets(RESPONSE~., data=GermanCredit, nbest=1, nvmax=11)

plot(choix, scale="adjr2", col="midnightblue")
plot(choix, scale="bic", col="midnightblue")
plot(choix, scale="Cp", col="midnightblue")
```

On peut constater que la plupart des colonnes ne sont jamais prises en compte et également que les 3 colonnes `CHK_ACCT`, `DURATION` et `HISTORY` sont souvent retenues, peu importe le critère d'information utilisé.

Nous avons ensuite créé un nouveau modèle utilisant seulement ces 3 meilleurs variables explicatives :

```{r}
#LM avec les 3 meilleurs variables
GermanCredit.lmReduced = lm(RESPONSE~CHK_ACCT+DURATION+HISTORY, data=GermanCredit)
summary(GermanCredit.lmReduced)
```

Malheureusement, avec un coefficient de détermination $R^2$ de `0.1805`, les résultats sont moins bon qu'avec le modèle précédent ($R^2 = 0.2712$).

Nous avons également essayé de prendre plus de variables (parmis celles qui ont été retenues dans les graphiques ci-dessus) :

```{r}
GermanCredit.lmReduced2 = lm(RESPONSE~CHK_ACCT+DURATION+HISTORY+NEW_CAR+EDUCATION+SAV_ACCT+INSTALL_RATE+MALE_SINGLE+GUARANTOR+OTHER_INSTALL, data=GermanCredit)
summary(GermanCredit.lmReduced2)
```

Avec un coefficient de détermination de `0.2396`, ce nouveau modèle se rapproche du modèle initial qui comportait toutes les variables explicatives.

On peut donc en conclure que la mauvaise performance de notre modèle n'est pas dû à la forte présence de bruit mais que c'est plutôt le modèle en question qui n'est pas adapté.

Nous avons donc décidé de changer de modèle et d'utiliser une regression logistique.

## Regression logistique

Après quelques recherches, nous avons appris que la regression logistique est particulièrement adaptées lorsque la variable de réponse est catégorielle, ce qui est notre cas.

Création du modèle de regression logistique avec toutes les variables disponibles :
```{r}
# GLM avec toutes nos variables
GermanCredit.glm = glm(RESPONSE~., data=GermanCredit, family = binomial)
summary(GermanCredit.glm)
```

Après analyse du résumé ci-dessus, nous avons reconstruit un modèle, mais cette fois avec toutes les variables qui ont un code de signification inférieur à 5%.

```{r}
# GLM avec les meilleures variables 
GermanCredit.glmReduced = glm(RESPONSE~CHK_ACCT+DURATION+HISTORY+NEW_CAR+AMOUNT+SAV_ACCT+INSTALL_RATE+MALE_SINGLE+GUARANTOR+OTHER_INSTALL+FOREIGN, data=GermanCredit, family = binomial)

AIC(GermanCredit.glmReduced)
```

On peut utiliser le critère AIC pour comparer ces deux modèles. Le second avec un ensemble de variables réduit obtient un AIC de `962.1353` contre un AIC de `975.37` pour le premier. Le second est donc meilleur.

## Vérification du modèle

Maintenant la régression logistique effectuée, nous allons tracer quelques graphes qui nous permettront de vérifier si le modèle est adéquat et qu'il est bien ajusté.

### Résidus de la régression
On commence par l'histogramme des résidus :
```{r}
residuals <- residuals(GermanCredit.glmReduced, type="deviance")

ggplot(data.frame(residuals), aes(x = residuals)) +
  geom_histogram(binwidth = 0.5, fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogramme des résidus", x = "Résidus de déviance", y = "Fréquence") +
  theme_minimal()
```

Dans l'idéal, on devrait obtenir une distribution normale, unimodale, symétrique et centrée autour de zéro. 

Malheureusement, notre modèle ne passe pas vraiment le test. Notre distribution est bimodale, pas symétrique et pas centrée sur zéro.

Il peut y avoir plusieurs raisons possibles à cela :

- Il existe des dépendances entre certaines de nos variables non-détectées par le modèle. Étant donné qu'il s'agit de données bancaires, cela est très probable
- Un grand nombre de valeurs atypiques pourrait aussi empêcher un bon ajustement du modèle.
- Une hétéroscédasticité, soit une variance inégale des résidus.

### Coefficients et intervalles de confiance
```{r}
# Extract coefficients and confidence intervals
coef_df <- as.data.frame(summary(GermanCredit.glmReduced)$coefficients)
coef_df$variable <- rownames(coef_df)
colnames(coef_df) <- c("Estimate", "Std.Error", "z.value", "p.value", "variable")

# Create the plot
ggplot(coef_df, aes(x = reorder(variable, Estimate), y = Estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = Estimate - 1.96 * Std.Error, ymax = Estimate + 1.96 * Std.Error), width = 0.2) +
  coord_flip() +
  labs(title = "Coefficient Plot", x = "Variables", y = "Estimates") +
  theme_minimal()
```

Dans le meilleur des cas, on ne devrait avoir que des variables dont la variance ne comprend pas zéro. Notre modèle est en accord avec cela.
Il y a juste `AMOUNT` qui est très proche de zéro, ce qui semble indiquer que le montant du crédit n'est pas un si bon indicateur de son risque, c'est un résultat intéressant. `DURATION` est similaire.

Pourtant, si on retire ces deux variables de la régression logistique, on obtient un AIC plus grand, ce qui indique un modèle moins performant.

### Courbe ROC (Receiver Operating Characteristic)
```{r}
# Predict probabilities
prob <- predict(GermanCredit.glmReduced, type = "response")

# Create ROC curve
roc_curve <- roc(GermanCredit$RESPONSE, prob)

# Plot ROC curve
ggroc(roc_curve) +
  labs(title = "ROC Curve glm", x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal()
```

Un mauvais modèle aurait une courbe ROC linéaire (aléatoire). Dans notre cas, elle tend vers le coin en haut à gauche du graphe, ce qui est bon signe.

## Analyse des résultats

### Impact de l'âge sur la variable de réponse
```{r}
# Add a new column for predicted probabilities
GermanCredit$predicted_prob <- predict(GermanCredit.glm, type = "response")

# Create the plot
ggplot(GermanCredit, aes(x = AGE, y = predicted_prob)) +
  geom_point(alpha = 0.5) +  # Scatter plot of predicted probabilities
  geom_smooth(method = "loess", color = "blue") +  # Smoothed line
  labs(title = "Predicted Probabilities vs Age",
       x = "Age",
       y = "Predicted Probability") +
  theme_minimal()
```

### CHK_ACCT
```{r}
# Add a new column for predicted probabilities
GermanCredit$predicted_prob <- predict(GermanCredit.glm, type = "response")

# Create the plot
ggplot(GermanCredit, aes(x = CHK_ACCT, y = predicted_prob)) +
  geom_point(alpha = 0.5) +  # Scatter plot of predicted probabilities
  geom_smooth(method = "loess", color = "blue") +  # Smoothed line
  labs(title = "Predicted Probabilities vs CHK_ACCT",
       x = "CHK_ACCT",
       y = "Predicted Probability") +
  theme_minimal()
```

### Boxplots
```{r}
# Create a boxplot for each level of CHK_ACCT
ggplot(GermanCredit.glm, aes(x = as.factor(CHK_ACCT), y = RESPONSE)) +
  geom_boxplot() +
  labs(title = "Boxplot of RESPONSE by CHK_ACCT Levels",
       x = "CHK_ACCT",
       y = "RESPONSE") +
  theme_minimal()
```
```{r}
# Boxplot for DURATION
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = DURATION)) +
  geom_boxplot() +
  labs(title = "Boxplot of DURATION by RESPONSE",
       x = "RESPONSE",
       y = "DURATION") +
  theme_minimal()

# Boxplot for MALE_SINGLE
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = MALE_SINGLE)) +
  geom_boxplot() +
  labs(title = "Boxplot of MALE_SINGLE by RESPONSE",
       x = "RESPONSE",
       y = "MALE_SINGLE") +
  theme_minimal()

# Boxplot for AMOUNT
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = AMOUNT)) +
  geom_boxplot() +
  labs(title = "Boxplot of AMOUNT by RESPONSE",
       x = "RESPONSE",
       y = "AMOUNT") +
  theme_minimal()

# Boxplot for AGE
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE), y = AGE)) +
  geom_boxplot() +
  labs(title = "Boxplot of AGE by RESPONSE",
       x = "RESPONSE",
       y = "AGE") +
  theme_minimal()
```

### Histogram
```{r}
# Create histograms for each level of CHK_ACCT
ggplot(GermanCredit.glm, aes(x = as.factor(RESPONSE))) +
  geom_histogram(stat = "count", fill = "steelblue", color = "black") +
  facet_wrap(~ CHK_ACCT) +
  labs(title = "Histogram of RESPONSE by CHK_ACCT Levels",
       x = "RESPONSE",
       y = "Count") +
  theme_minimal()
```

```{r}
# Create a stacked bar plot of the proportion of RESPONSE for each CHK_ACCT level
ggplot(GermanCredit.glm, aes(x = as.factor(CHK_ACCT), fill = as.factor(RESPONSE))) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(title = "Proportion of RESPONSE by CHK_ACCT Levels",
       x = "CHK_ACCT",
       y = "Proportion",
       fill = "RESPONSE") +
  theme_minimal()
```

## Conclusion

Avec tout ces modèles, nous pouvons déduire certaines hypothèse :

- Le modèle de régression logistique est plus adapté lorsque nous utilisons plusieurs type de variables.
- Un modèle utilisant en entrée seulement les variables explicatives significatives est meilleur qu'un model utilisant simplement toutes les variables.

Nous pouvons aussi déduire grâce a nos résultats et aux différents graphique l'importance des différentes variables.
Nous pouvons citer :

- `CHK_ACCT`
- `AMOUNT`
- Ou encore `DURATION`

Néanmoins il y a quelques variables qui semblaient être importantes, mais qui le sont pas du tout ou très peu.
Nous avons : 

- `AGE`
- Ou encore `EMPLOYMENT`